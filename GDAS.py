import numpy as np
from sklearn.utils import resample
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier


def bootstrap_variance(accuracies):
    """
    T√≠nh ph∆∞∆°ng sai bootstrap t·ª´ danh s√°ch ƒë·ªô ch√≠nh x√°c.
    """
    B = len(accuracies)
    mean_acc = np.mean(accuracies)
    variance = sum([(acc - mean_acc) ** 2 for acc in accuracies]) / (B - 1)
    return variance


def GDAS(X, y, model, epsilon=0.01, delta=0.05, bootstrap_iterations=100):
    """
    Th·ª±c hi·ªán thu·∫≠t to√°n Generalized Dynamic Adaptive Sampling (GDAS)

    Parameters:
        X: D·ªØ li·ªáu ƒë·∫ßu v√†o
        y: Nh√£n
        model: M√¥ h√¨nh h·ªçc m√°y (v√≠ d·ª•: DecisionTreeClassifier)
        epsilon: Ng∆∞·ª°ng sai s·ªë cho h·ªôi t·ª•
        delta: X√°c su·∫•t ch·∫•p nh·∫≠n sai s·ªë
        bootstrap_iterations: s·ªë l∆∞·ª£ng bootstrap ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng ph∆∞∆°ng sai

    Returns:
        Danh s√°ch c√°c m·∫´u, ƒë·ªô ch√≠nh x√°c ·ª©ng v·ªõi m·ªói b∆∞·ªõc, t·ªïng s·ªë m·∫´u ƒë√£ d√πng
    """
    n_total = len(X)
    indices = np.arange(n_total)
    np.random.shuffle(indices)

    results = []
    used_indices = set()

    # B·∫Øt ƒë·∫ßu v·ªõi 10% d·ªØ li·ªáu
    sample_size = max(int(0.1 * n_total), 10)
    prev_acc = 0.0
    converged = False
    step = 1

    while not converged and sample_size < n_total:
        current_indices = np.random.choice(list(set(indices) - used_indices), sample_size, replace=False)
        used_indices.update(current_indices)
        X_sample, y_sample = X[current_indices], y[current_indices]

        # Hu·∫•n luy·ªán v√† t√≠nh ƒë·ªô ch√≠nh x√°c
        model.fit(X_sample, y_sample)
        y_pred = model.predict(X_sample)
        current_acc = accuracy_score(y_sample, y_pred)

        # T√≠nh ph∆∞∆°ng sai bootstrap
        bootstrapped_accs = []
        for _ in range(bootstrap_iterations):
            X_bs, y_bs = resample(X_sample, y_sample)
            model.fit(X_bs, y_bs)
            y_bs_pred = model.predict(X_bs)
            acc_bs = accuracy_score(y_bs, y_bs_pred)
            bootstrapped_accs.append(acc_bs)

        var_boot = bootstrap_variance(bootstrapped_accs)
        p_hat = abs(current_acc - prev_acc)

        # T√≠nh s·ªë m·∫´u m c·∫ßn th√™m theo BƒêT Chebyshev
        if p_hat != 0:
            m_required = int((var_boot / (delta * (epsilon ** 2))) + 1)
        else:
            m_required = 0

        # L∆∞u k·∫øt qu·∫£
        results.append({
            'step': step,
            'sample_size': len(used_indices),
            'accuracy': current_acc,
            'variance': var_boot,
            'p_hat': p_hat
        })

        print(
            f"[Step {step}] Sample Size: {len(used_indices)} | Accuracy: {current_acc:.4f} | pÃÇ: {p_hat:.4f} | œÉ¬≤_boot: {var_boot:.4f}")

        # Ki·ªÉm tra h·ªôi t·ª•
        if (p_hat < epsilon) and (var_boot / (bootstrap_iterations * (epsilon ** 2)) <= delta):
            converged = True
        else:
            sample_size = m_required
            prev_acc = current_acc
            step += 1

    return results


def GDAS_with_samples(X, y, model, epsilon=0.01, delta=0.05, bootstrap_iterations=100):
    n_total = len(X)
    indices = np.arange(n_total)
    np.random.shuffle(indices)

    results = []
    used_indices = set()
    sample_snapshots = []

    sample_size = max(int(0.1 * n_total), 10)
    prev_acc = 0.0
    converged = False
    step = 1

    while not converged and len(used_indices) + sample_size <= n_total:
        current_indices = np.random.choice(list(set(indices) - used_indices), sample_size, replace=False)
        used_indices.update(current_indices)
        X_sample, y_sample = X[list(used_indices)], y[list(used_indices)]

        model.fit(X_sample, y_sample)
        y_pred = model.predict(X_sample)
        current_acc = accuracy_score(y_sample, y_pred)

        bootstrapped_accs = []
        for _ in range(bootstrap_iterations):
            X_bs, y_bs = resample(X_sample, y_sample)
            model.fit(X_bs, y_bs)
            y_bs_pred = model.predict(X_bs)
            acc_bs = accuracy_score(y_bs, y_bs_pred)
            bootstrapped_accs.append(acc_bs)

        var_boot = bootstrap_variance(bootstrapped_accs)
        p_hat = abs(current_acc - prev_acc)

        if p_hat != 0:
            m_required = int((var_boot / (delta * (epsilon ** 2))) + 1)
        else:
            m_required = 0

        # L∆∞u th√¥ng tin
        results.append({
            'step': step,
            'sample_size': len(used_indices),
            'accuracy': current_acc,
            'variance': var_boot,
            'p_hat': p_hat
        })
        sample_snapshots.append(sorted(list(used_indices)))  # l∆∞u c√°c ch·ªâ s·ªë m·∫´u

        print(
            f"[Step {step}] Sample Size: {len(used_indices)} | Accuracy: {current_acc:.4f} | pÃÇ: {p_hat:.4f} | œÉ¬≤_boot: {var_boot:.4f}")

        if (p_hat < epsilon) and (var_boot / (bootstrap_iterations * (epsilon ** 2)) <= delta):
            converged = True
        else:
            sample_size = m_required
            prev_acc = current_acc
            step += 1

    return results, sample_snapshots

from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier

# T·∫£i d·ªØ li·ªáu Iris
iris = load_iris()
X = iris.data
y = iris.target

model = DecisionTreeClassifier(random_state=42)

# G·ªçi h√†m GDAS c√≥ l∆∞u m·∫´u
results, sample_snapshots = GDAS_with_samples(X, y, model)
#
# # In ra c√°c ch·ªâ s·ªë m·∫´u t·ª´ng b∆∞·ªõc
# for i, sample in enumerate(sample_snapshots, 1):
#     print(f"\n[Sample Step {i}] - Sample Size: {len(sample)}")
#     print("Indices:", sample)
#
# # D·ªØ li·ªáu ƒë∆∞·ª£c ch·ªçn ·ªü b∆∞·ªõc cu·ªëi
# final_sample_indices = sample_snapshots[-1]
# X_cut = X[final_sample_indices]
# y_cut = y[final_sample_indices]
#
# print("X_cut shape:", X_cut.shape)   # v√≠ d·ª•: (48, 4)
# print("y_cut distribution:", np.bincount(y_cut))

import numpy as np
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt

# T·∫£i d·ªØ li·ªáu Iris
iris = load_iris()
X, y = iris.data, iris.target
class_names = iris.target_names

# Ph√¢n b·ªë l·ªõp trong to√†n b·ªô d·ªØ li·ªáu
original_counts = np.bincount(y)

# Ph√¢n b·ªë l·ªõp sau khi c·∫Øt b·∫±ng GDAS
final_sample_indices = sample_snapshots[-1]
y_cut = y[final_sample_indices]
cut_counts = np.bincount(y_cut)

# In ph√¢n b·ªë l·ªõp
print("üåº Ph√¢n b·ªë l·ªõp trong to√†n b·ªô d·ªØ li·ªáu:")
for i, c in enumerate(original_counts):
    print(f" - {class_names[i]}: {c} m·∫´u")

print("\n‚úÇÔ∏è Ph√¢n b·ªë l·ªõp sau khi c·∫Øt b·∫±ng GDAS:")
for i, c in enumerate(cut_counts):
    print(f" - {class_names[i]}: {c} m·∫´u")

# x_labels = class_names
# x = np.arange(len(x_labels))  # [0, 1, 2]
#
# plt.bar(x - 0.15, original_counts, width=0.3, label='D·ªØ li·ªáu g·ªëc')
# plt.bar(x + 0.15, cut_counts, width=0.3, label='D·ªØ li·ªáu c·∫Øt')
#
# plt.xticks(x, x_labels)
# plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")
# plt.title("So s√°nh ph√¢n b·ªë l·ªõp tr∆∞·ªõc v√† sau khi c·∫Øt b·∫±ng GDAS")
# plt.legend()
# plt.grid(True, linestyle="--", alpha=0.5)
# plt.tight_layout()
# plt.show()


import pandas as pd

# T·∫°o DataFrame t·ª´ d·ªØ li·ªáu ƒë√£ c·∫Øt
X_cut = X[final_sample_indices]
y_cut = y[final_sample_indices]
df_cut = pd.DataFrame(X_cut, columns=iris.feature_names)
df_cut['target'] = y_cut
df_cut['target_name'] = df_cut['target'].apply(lambda x: class_names[x])

# L∆∞u ra file CSV
df_cut.to_csv("iris_gdas_sample.csv", index=False, encoding='utf-8-sig')
print("ƒê√£ l∆∞u t·∫≠p d·ªØ li·ªáu ƒë√£ c·∫Øt v√†o 'iris_gdas_sample.csv'")



